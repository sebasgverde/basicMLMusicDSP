{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sources\n",
    "\n",
    "https://github.com/librosa/librosa\n",
    "\n",
    "https://magenta.tensorflow.org/onsets-frames\n",
    "\n",
    "http://pythonforengineers.com/audio-and-digital-signal-processingdsp-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First generate a sin wave and save it as wav file http://pythonforengineers.com/audio-and-digital-signal-processingdsp-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "import wave\n",
    " \n",
    "import struct\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "num_samples = 48000\n",
    "# The sampling rate of the analog to digital convert\n",
    "sampling_rate = 48000.0\n",
    "amplitude = 16000\n",
    "# creates a sine wave with the given frequence of one seconde and a silence of one second\n",
    "def make_sound_and_silence(freq=1000):\n",
    "    # frequency is the number of times a wave repeats a second\n",
    "\n",
    "    frequency = freq\n",
    "\n",
    "    sine_wave_part = [np.sin(2 * np.pi * frequency * x/sampling_rate) for x in range(num_samples)] + [0] * num_samples\n",
    "\n",
    "    return sine_wave_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nframes=num_samples\n",
    "comptype=\"NONE\"\n",
    "compname=\"not compressed\"\n",
    "nchannels=1\n",
    "sampwidth=2\n",
    "\n",
    "# recieves and array with a sine wave and creates a wav file\n",
    "def save_wav(sine_wave, file = \"test.wav\"):\n",
    "    wav_file=wave.open(file, 'w')\n",
    "\n",
    "    wav_file.setparams((nchannels, sampwidth, int(sampling_rate), nframes, comptype, compname))\n",
    "\n",
    "    for s in sine_wave:\n",
    "       wav_file.writeframes(struct.pack('h', int(s*amplitude)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "little_sine_wave = make_sound_and_silence(1000)\n",
    "\n",
    "print(little_sine_wave[:10])\n",
    "print(len(little_sine_wave))\n",
    "\n",
    "save_wav(little_sine_wave, \"shorttest.wav\")\n",
    "print(\"ready!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# We'll need numpy for some mathematical operations\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline\n",
    "\n",
    "# and IPython.display for audio output\n",
    "import IPython.display\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "# And the display module for visualization\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the example track\n",
    "y, sr = librosa.load(\"shorttest.wav\")\n",
    "\n",
    "# Play it back!\n",
    "IPython.display.Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sine_wave=[]\n",
    "for i in range(1,11):\n",
    "    sine_wave += make_sound_and_silence(500*i)\n",
    "\n",
    "print(sine_wave[:10])\n",
    "print(len(sine_wave))\n",
    "\n",
    "save_wav(sine_wave, \"longtest.wav\")\n",
    "print(\"ready!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load(\"longtest.wav\")\n",
    "IPython.display.Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load wav and paint the spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "\n",
    "# Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "# Make a new figure\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "# Display the spectrogram on a mel scale\n",
    "# sample rate and hop length parameters are used to render the time axis\n",
    "librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n",
    "\n",
    "# Put a descriptive title on the plot\n",
    "plt.title('mel power spectrogram')\n",
    "\n",
    "# draw a color bar\n",
    "plt.colorbar(format='%+02.0f dB')\n",
    "\n",
    "# Make the figure layout compact\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"testSpectrogram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "log_S = librosa.power_to_db(S, ref=np.max)\n",
    "plt.figure(figsize=(12,4))\n",
    "librosa.display.specshow(log_S, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create a dataset with each second of a wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset with each second of a wav\n",
    "def create_dataset(audio_path, dataset_name=\"dataset\"):\n",
    "    \n",
    "    y, sr = librosa.load(audio_path)\n",
    "\n",
    "    #use sr (sampling rate) to split data in seconds\n",
    "    import os \n",
    "    if not os.path.exists(dataset_name):\n",
    "        os.makedirs(dataset_name)\n",
    "\n",
    "    initial = 0\n",
    "    final = sr\n",
    "    for i in range(len(y)/sr):\n",
    "        # Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "        S = librosa.feature.melspectrogram(y[initial:final], sr=sr, n_mels=128)\n",
    "\n",
    "        # Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "        log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        # Make a new figure\n",
    "        plt.figure(figsize=(12,4))\n",
    "\n",
    "\n",
    "        # Display the spectrogram on a mel scale\n",
    "        # sample rate and hop length parameters are used to render the time axis\n",
    "        librosa.display.specshow(log_S, sr=sr)    \n",
    "\n",
    "        #create dataset with 0 for silence and 1 for sound\n",
    "        if i % 2 == 0:\n",
    "            plt.savefig(dataset_name + \"/second_\"+str(i)+\"_label_1.png\")\n",
    "        else:\n",
    "            plt.savefig(dataset_name + \"/second_\"+str(i)+\"_label_0.png\")\n",
    "        initial += sr\n",
    "        final += sr\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(\"longtest.wav\")\n",
    "\n",
    "print(len(y))\n",
    "print(sr)\n",
    "len(y)/sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "def load_data(folder = \"dataset\"):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for image in os.listdir(folder):\n",
    "        print(image)\n",
    "        images.append(plt.imread(folder + \"/\" + image))\n",
    "        labels.append(int(image.split(\"_\")[3].split(\".\")[0]))\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    print(labels)\n",
    "    images.shape\n",
    "\n",
    "    # To apply a classifier on this data, we need to flatten the image, to\n",
    "    # turn the data in a (samples, feature) matrix:\n",
    "    n_samples = len(images)\n",
    "    data = images.reshape((n_samples, -1))\n",
    "    \n",
    "    return data, images, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, images, labels = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,4))\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_and_labels = list(zip(images, labels))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i\\n' % label, fontsize = 20)\n",
    "    \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# all parameters not specified are set to their defaults\n",
    "logisticRegr = LogisticRegression()\n",
    "\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "\n",
    "predictions = logisticRegr.predict(x_test)\n",
    "print(\"Predictions for test:\")\n",
    "print(predictions)\n",
    "\n",
    "# Use score method to get accuracy of model\n",
    "score = logisticRegr.score(x_test, y_test)\n",
    "print(\"score:\")\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass classification (musical notes)\n",
    "\n",
    "Using https://pages.mtu.edu/~suits/notefreqs.html begining with central C (C4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset with each second of a wav\n",
    "def create_dataset_notes(audio_path, dataset_name=\"notesdataset\"):\n",
    "    \n",
    "    y, sr = librosa.load(audio_path)\n",
    "    \n",
    "    labels = audio_path.split(\"_\")\n",
    "\n",
    "    #use sr (sampling rate) to split data in seconds\n",
    "    import os \n",
    "    if not os.path.exists(dataset_name):\n",
    "        os.makedirs(dataset_name)\n",
    "\n",
    "    initial = 0\n",
    "    final = sr\n",
    "    for i in range(len(y)/sr):\n",
    "        # Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "        S = librosa.feature.melspectrogram(y[initial:final], sr=sr, n_mels=128)\n",
    "\n",
    "        # Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "        log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "        # Make a new figure\n",
    "        plt.figure(figsize=(12,4))\n",
    "\n",
    "\n",
    "        # Display the spectrogram on a mel scale\n",
    "        # sample rate and hop length parameters are used to render the time axis\n",
    "        librosa.display.specshow(log_S, sr=sr)    \n",
    "\n",
    "        #create dataset with 0 for silence and 1 for sound\n",
    "        if i % 2 == 0:\n",
    "            plt.savefig(dataset_name + \"/second_\"+str(i)+\"_label_\" + labels[i/2] + \".png\")\n",
    "        else:\n",
    "            # we only want the notes in this case\n",
    "            print(\"nothing\")\n",
    "            #plt.savefig(dataset_name + \"/second_\"+str(i)+\"_label_0.png\")\n",
    "        initial += sr\n",
    "        final += sr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = {\"C\" : 261.63, \"D\" : 293.66, \"E\" : 329.63, \"F\" : 349.23, \"G\" : 392.00, \"A\" : 440.00, \"B\" : 493.88}\n",
    "labels_dict = { \"silence\" : 0,\"C\" : 1, \"D\" : 2, \"E\" : 3, \"F\" : 4, \"G\" : 5, \"A\" : 6, \"B\" : 7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "sine_wave=[]\n",
    "file_name = \"\"\n",
    "for i in range(0,20):\n",
    "    rand_note = random.choice(notes.keys())\n",
    "    file_name += str(labels_dict[rand_note]) + \"_\"\n",
    "    sine_wave += make_sound_and_silence(notes[rand_note])\n",
    "\n",
    "print(sine_wave[:10])\n",
    "print(len(sine_wave))\n",
    "\n",
    "wav_name = file_name + \"notes.wav\"\n",
    "save_wav(sine_wave, wav_name)\n",
    "print(\"ready!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "create_dataset_notes(wav_name, \"datasetnotes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, images, labels = load_data(\"datasetnotes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM http://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images_and_labels = list(zip(images, labels))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "    \n",
    "n_samples = len(images)\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifierSVM = svm.SVC(gamma=0.001)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifierSVM.fit(data[:n_samples // 2], labels[:n_samples // 2])\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = labels[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifierSVM, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "images_and_predictions = list(zip(images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the train models as pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(logisticRegr, open('logisticRegr.p','wb'))\n",
    "pickle.dump(classifierSVM, open('classifierSVM.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_logreg = pickle.load(file('logisticRegr.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_logreg.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_svm = pickle.load(file('classifierSVM.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_svm.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
