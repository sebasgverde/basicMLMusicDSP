{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some sources\n",
    "\n",
    "https://github.com/librosa/librosa\n",
    "\n",
    "https://magenta.tensorflow.org/onsets-frames\n",
    "\n",
    "http://pythonforengineers.com/audio-and-digital-signal-processingdsp-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First generate a sin wave and save it as wav file http://pythonforengineers.com/audio-and-digital-signal-processingdsp-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    " \n",
    "import wave\n",
    " \n",
    "import struct\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# frequency is the number of times a wave repeats a second\n",
    " \n",
    "frequency = 1000\n",
    " \n",
    "num_samples = 48000\n",
    " \n",
    "# The sampling rate of the analog to digital convert\n",
    " \n",
    "sampling_rate = 48000.0\n",
    " \n",
    "amplitude = 16000\n",
    " \n",
    "file = \"test.wav\"\n",
    "\n",
    "sine_wave_part = [np.sin(2 * np.pi * frequency * x/sampling_rate) for x in range(num_samples)] + [0] * num_samples + [np.sin(2 * np.pi * frequency*2 * x/sampling_rate) for x in range(num_samples)] + [0] * num_samples\n",
    "\n",
    "for i in range(10):\n",
    "    sine_wave += sine_wave_part\n",
    "\n",
    "print(sine_wave[:10])\n",
    "print(len(sine_wave))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nframes=num_samples\n",
    " \n",
    "comptype=\"NONE\"\n",
    " \n",
    "compname=\"not compressed\"\n",
    " \n",
    "nchannels=1\n",
    " \n",
    "sampwidth=2\n",
    "\n",
    "\n",
    "wav_file=wave.open(file, 'w')\n",
    " \n",
    "wav_file.setparams((nchannels, sampwidth, int(sampling_rate), nframes, comptype, compname))\n",
    "\n",
    "for s in sine_wave:\n",
    "   wav_file.writeframes(struct.pack('h', int(s*amplitude)))\n",
    "\n",
    "print(\"ready!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load wav and paint the spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# We'll need numpy for some mathematical operations\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline\n",
    "\n",
    "# and IPython.display for audio output\n",
    "import IPython.display\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "# And the display module for visualization\n",
    "import librosa.display\n",
    "\n",
    "audio_path = 'test.wav'\n",
    "\n",
    "y, sr = librosa.load(audio_path)\n",
    "\n",
    "# Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "\n",
    "# Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "# Make a new figure\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "# Display the spectrogram on a mel scale\n",
    "# sample rate and hop length parameters are used to render the time axis\n",
    "librosa.display.specshow(log_S, sr=sr, x_axis='time', y_axis='mel')\n",
    "\n",
    "# Put a descriptive title on the plot\n",
    "plt.title('mel power spectrogram')\n",
    "\n",
    "# draw a color bar\n",
    "plt.colorbar(format='%+02.0f dB')\n",
    "\n",
    "# Make the figure layout compact\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"testSpectrogram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# We'll need numpy for some mathematical operations\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline\n",
    "\n",
    "# and IPython.display for audio output\n",
    "import IPython.display\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "# And the display module for visualization\n",
    "import librosa.display\n",
    "\n",
    "audio_path = 'test.wav'\n",
    "\n",
    "y, sr = librosa.load(audio_path)\n",
    "\n",
    "# Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "\n",
    "# Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "# Make a new figure\n",
    "plt.figure(figsize=(12,4))\n",
    "\n",
    "\n",
    "# Display the spectrogram on a mel scale\n",
    "# sample rate and hop length parameters are used to render the time axis\n",
    "librosa.display.specshow(log_S, sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "# We'll need numpy for some mathematical operations\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib for displaying the output\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline\n",
    "\n",
    "# and IPython.display for audio output\n",
    "import IPython.display\n",
    "\n",
    "# Librosa for audio\n",
    "import librosa\n",
    "# And the display module for visualization\n",
    "import librosa.display\n",
    "\n",
    "audio_path = 'test.wav'\n",
    "\n",
    "y, sr = librosa.load(audio_path)\n",
    "\n",
    "#use sr (sampling rate) to split data in seconds\n",
    "import os \n",
    "if not os.path.exists(\"dataset\"):\n",
    "    os.makedirs(\"dataset\")\n",
    "    \n",
    "initial = 0\n",
    "final = sr\n",
    "for i in range(len(y)/sr):\n",
    "    # Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "    S = librosa.feature.melspectrogram(y[initial:final], sr=sr, n_mels=128)\n",
    "\n",
    "    # Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "\n",
    "    # Make a new figure\n",
    "    plt.figure(figsize=(12,4))\n",
    "\n",
    "\n",
    "    # Display the spectrogram on a mel scale\n",
    "    # sample rate and hop length parameters are used to render the time axis\n",
    "    librosa.display.specshow(log_S, sr=sr)    \n",
    "    \n",
    "    #create dataset with 0 for silence and 1 for sound\n",
    "    if i % 2 == 0:\n",
    "        plt.savefig(\"dataset/second_\"+str(i)+\"_label_1.png\")\n",
    "    else:\n",
    "        plt.savefig(\"dataset/second_\"+str(i)+\"_label_0.png\")\n",
    "    initial += sr\n",
    "    final += sr\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y))\n",
    "print(sr)\n",
    "len(y)/sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Author: Gael Varoquaux <gael dot varoquaux at normalesup dot org>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "# Print to show there are 1797 images (8 by 8 images for a dimensionality of 64)\n",
    "print(\"Image Data Shape\" , digits.data.shape)\n",
    "# Print to show there are 1797 labels (integers from 0â€“9)\n",
    "print(\"Label Data Shape\", digits.target.shape)\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,4))\n",
    "for index, (image, label) in enumerate(zip(digits.data[0:5], digits.target[0:5])):\n",
    "    plt.subplot(1, 5, index + 1)\n",
    "    plt.imshow(np.reshape(image, (8,8)), cmap=plt.cm.gray)\n",
    "    plt.title('Training: %i\\n' % label, fontsize = 20)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=0)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# all parameters not specified are set to their defaults\n",
    "logisticRegr = LogisticRegression()\n",
    "\n",
    "logisticRegr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a NumPy Array\n",
    "# Predict for One Observation (image)\n",
    "logisticRegr.predict(x_test[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegr.predict(x_test[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = logisticRegr.predict(x_test)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Use score method to get accuracy of model\n",
    "score = logisticRegr.score(x_test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"hello\")\n",
    "a = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(a, open('test.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"load pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = pickle.load(file('test.p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
